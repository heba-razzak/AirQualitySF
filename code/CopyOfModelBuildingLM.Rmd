---
title: "Model Building LM"
output: github_document
knit: (function(input, ...) {rmarkdown::render(input, output_dir = "../docs", )})
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(fig.path = "../docs/plots/")
```

Load required libraries

```{r, load-libraries, message = FALSE, warning = FALSE}
library(dplyr)         # For data manipulation
library(data.table)    # Working with large files
library(ggplot2)       # Plots
library(timeDate)
```

Read files 

```{r, read-purpleair-csv, echo = FALSE, results = "hide", message = FALSE}
purpleair_data <- data.frame(fread(file.path("data", "raw", "purpleair_2018-01-01_2019-12-31.csv")))
```


```{r}
# data_dictionary(dataset_lr, hide = c("N_Unique", "top_n"))
```

```{r}
dataset_lr <- purpleair_data %>% 
  select(pm2.5_alt, time_stamp, sensor_index, rssi, uptime, memory, humidity, temperature, pressure,
         analog_input, location_type) %>% rename(target = pm2.5_alt) %>% distinct
dataset_lr <- dataset_lr %>% mutate(pressure = ifelse(is.na(pressure),-1,pressure))

holidays <- as.Date(c(holidayNYSE(2019), holidayNYSE(2018)))

dataset_lr <- dataset_lr %>%
  mutate(
    time_stamp = lubridate::as_datetime(time_stamp),
    local_timestamp = lubridate::with_tz(time_stamp, tzone = "America/Los_Angeles"),
    local_date = as.Date(local_timestamp, tz="America/Los_Angeles"),
    dow = lubridate::wday(local_timestamp),
    hour = lubridate::hour(local_timestamp),
    day = lubridate::day(local_timestamp),
    month = lubridate::month(local_timestamp),
    year = ifelse(lubridate::year(local_timestamp) == 2019, 1, 0),
    holiday = ifelse(local_date %in% holidays, 1, 0)
  ) %>% select(-local_date, -local_timestamp)
```

<!-- # LSTM -->
<!-- ```{r} -->
<!-- library(keras) -->

<!-- normalize <- function(x) { -->
<!--   return((x - min(x)) / (max(x) - min(x))) -->
<!-- } -->

<!-- dataset_lr_scaled <- as.data.frame(lapply(dataset_lr, normalize)) -->

<!-- ``` -->

<!-- ```{r} -->
<!-- create_sequences <- function(data, n_timesteps) { -->
<!--   X <- array(NA, dim = c(nrow(data) - n_timesteps, n_timesteps, ncol(data) - 1)) -->
<!--   y <- array(NA, dim = c(nrow(data) - n_timesteps, 1)) -->

<!--   for (i in 1:(nrow(data) - n_timesteps)) { -->
<!--     X[i, , ] <- as.matrix(data[i:(i + n_timesteps - 1), 1:(ncol(data) - 1)]) -->
<!--     y[i] <- data[i + n_timesteps, ncol(data)]  # Target column (the one you are predicting) -->
<!--   } -->

<!--   list(X = X, y = y) -->
<!-- } -->

<!-- # Define timesteps (for example, 24 timesteps if using hourly data for 1 day of history) -->
<!-- n_timesteps <- 24 -->
<!-- sequences <- create_sequences(dataset_lr_scaled, n_timesteps) -->
<!-- X_train <- sequences$X -->
<!-- y_train <- sequences$y -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Build the LSTM model -->
<!-- model <- keras_model_sequential() %>% -->
<!--   layer_lstm(units = 50, return_sequences = TRUE, input_shape = c(n_timesteps, ncol(dataset_lr_scaled) - 1)) %>% -->
<!--   layer_lstm(units = 50, return_sequences = FALSE) %>% -->
<!--   layer_dense(units = 25, activation = 'relu') %>% -->
<!--   layer_dense(units = 1) -->

<!-- # Compile the model -->
<!-- model %>% compile( -->
<!--   loss = 'mean_squared_error', -->
<!--   optimizer = 'adam' -->
<!-- ) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Train the LSTM model -->
<!-- model %>% fit( -->
<!--   X_train, -->
<!--   y_train, -->
<!--   epochs = 20,      # Adjust number of epochs for better results -->
<!--   batch_size = 32,  # Adjust batch size as needed -->
<!--   validation_split = 0.2  # Use part of the data for validation -->
<!-- ) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- # Make predictions -->
<!-- predictions <- model %>% predict(X_train) -->

<!-- # (Optional) Reverse normalization if needed -->
<!-- denormalize <- function(x, min_val, max_val) { -->
<!--   return(x * (max_val - min_val) + min_val) -->
<!-- } -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Calculate RMSE, MAE, or other metrics to evaluate performance -->
<!-- rmse <- sqrt(mean((predictions - y_train)^2)) -->
<!-- mae <- mean(abs(predictions - y_train)) -->

<!-- cat("RMSE:", rmse, "\n") -->
<!-- cat("MAE:", mae, "\n") -->
<!-- ``` -->


# Linear 

```{r}
dataset_lr <- dataset_lr %>%
  mutate(across(c("rssi", "uptime", "memory", "humidity",
                  "temperature", "pressure", "analog_input"), scale))
```

```{r}
dataset_lr <- na.omit(dataset_lr)

# Determine the index for the 70% split
split_index <- floor(0.7 * nrow(arrange(dataset_lr, time_stamp)))

# Find the date at this index
split_time <- dataset_lr %>% arrange(time_stamp) %>%
  pull(time_stamp) %>% .[split_index]

# Split the data into training and testing sets based on the split_time
train <- subset(dataset_lr, time_stamp <= split_time) %>% dplyr::select(-time_stamp, -sensor_index)
test <- subset(dataset_lr, time_stamp > split_time) 

# Save timestamp and sensor index for identifying problem areas
test_time_sensor <- test %>% select(time_stamp, sensor_index)

# Remove timestamp and sensor index from test set for model training
test <- test %>% dplyr::select(-time_stamp, -sensor_index)

# True labels for test data
test_label <- test$target

# Drop target column from test
test <- test %>% select(-target)

# Linear Regression Model
linear_model <- lm(target ~ ., data = train)
```




```{r}
# # Multicollinearity
# vif_values <- vif(linear_model)
# print("Variance Inflation Factors")
# print(vif_values)
# cat("--------------------------------------------------------------")
```


```{r}
# Summarize the model
print("Model Summary")
summary(linear_model)
cat("--------------------------------------------------------------")
```


```{r}
# Make predictions
linear_predictions <- predict(linear_model, newdata = test)

# Calculate performance metrics
# Mean Absolute Error (MAE)
mae_linear <- mean(abs(linear_predictions - test_label))
cat("\nLinear Regression MAE:", mae_linear)
```


```{r}
# Mean Absolute Percentage Error (MAPE)
# Replace zero values in test_label with a very small number
mape_test_label <- ifelse(test_label == 0, 0.00001, test_label)

# Calculate Mean Absolute Percentage Error (MAPE)
mape_linear <- mean(abs((linear_predictions - mape_test_label) / mape_test_label)) * 100
cat("\nLinear Regression MAPE:", mape_linear)
```


```{r}
# R-squared (R²)
ss_res_linear <- sum((linear_predictions - test_label)^2)
ss_tot_linear <- sum((test_label - mean(test_label))^2)
r2_linear <- 1 - (ss_res_linear / ss_tot_linear)
cat("\nLinear Regression R²:", r2_linear)
```


```{r}
# Adjusted R-squared
n_linear <- length(test_label)
p_linear <- ncol(test)
adj_r2_linear <- 1 - ((1 - r2_linear) * (n_linear - 1) / (n_linear - p_linear - 1))
cat("\nLinear Regression Adjusted R²:", adj_r2_linear)
```


```{r}
# Root Mean Squared Error (RMSE)
rmse_linear <- sqrt(mean((linear_predictions - test_label)^2))
cat("\nLinear Regression RMSE:", rmse_linear, "\n")
```


```{r}
# Create a dataframe with actual values, predicted values, absolute differences, and identification columns
results <- test %>%
  mutate(
    Actual = test_label,
    Predicted = linear_predictions,
    AbsDifference = abs(test_label - linear_predictions)
  ) %>%
bind_cols(test_time_sensor) %>%
  arrange(desc(AbsDifference))
```


```{r}
# Plot to show which days have the most errors
error_by_day <- results %>%
  mutate(date = as.Date(time_stamp)) %>%
  group_by(date) %>%
  summarize(TotalAbsDifference = sum(AbsDifference),
            AvgAbsDifference = mean(AbsDifference),
            MaxAbsDifference = max(AbsDifference),
            AbsDifference90p = quantile(AbsDifference, 0.9)) %>%
  arrange(date)

# Plot average, maximum, and 90th percentile absolute differences
ggplot(error_by_day, aes(x = date)) +
  geom_line(aes(y = AvgAbsDifference, color = "Average Absolute Difference")) +
  geom_line(aes(y = MaxAbsDifference, color = "Maximum Absolute Difference")) +
  geom_line(aes(y = AbsDifference90p, color = "90th Percentile Absolute Difference")) +
  labs(
    title = "Absolute Differences Over Time",
    x = "Date",
    y = "Absolute Difference"
  ) +
  scale_color_manual(
    values = c("Average Absolute Difference" = "blue",
               "Maximum Absolute Difference" = "red",
               "90th Percentile Absolute Difference" = "green")
  ) +
  theme_minimal()
```


```{r}
# Display the sorted results
print(error_by_day)
```


```{r}
# Plot residuals
residuals <- test_label - linear_predictions
plot(residuals, main = "Residuals Plot", ylab = "Residuals", xlab = "Index", col = "blue", pch = 20)
abline(h = 0, col = "red")

# Histogram of residuals
hist(residuals, breaks = 50, main = "Histogram of Residuals", xlab = "Residuals", col = "blue")
```


```{r}
# Plot predictions vs actual values
plot(test_label, linear_predictions, main = "Predictions vs Actual Values", xlab = "Actual Values", ylab = "Predicted Values", col = "blue", pch = 19)
abline(0, 1, col = "red")
```
