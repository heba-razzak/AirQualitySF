---
title: "Model Building"
output: github_document
---

# Model Building

```{r setup, include=FALSE}
preprocessing_directory <- readr::read_file("inputs/preprocessing_directory.txt")
```

## Load required libraries
```{r, load-libraries, message = FALSE, warning = FALSE}
library(lubridate) # For dates
library(dplyr) # For data manipulation
library(sf) # For working with spatial data
library(mapview) # to view maps
library(tidyr) # pivot
library(ggplot2) # plots
library(data.table) # Faster than dataframes (for big files)
```

## Read files
```{r, read-files}
dataset <- fread(paste0(preprocessing_directory, "/final_dataset.csv"))

# devtools::install_github("heba-razzak/createDataDict")
# library(createDataDict)
# 
# print_data_dict(dataset)
# # get dataframe for descriptions
# descriptions <- descriptions_df(dataset)
# 
# # update descriptions dataframe
# descriptions <- update_description(descriptions,
#                                    c("time_stamp", "pm2.5_atm", "pm2.5_atm_a", "pm2.5_atm_b", "sensor_index", "dow", "hour", 
#                                      "day", "month", "year", "wknd", "holiday", "building_area", "b_yes", "b_apartments", 
#                                      "b_house", "b_NA", "b_residential", "b_terrace", "b_other", "road_length", "r_footway", 
#                                      "r_residential", "r_service", "r_secondary", "r_primary", "r_tertiary", "r_steps", 
#                                      "r_path", "r_motorway_link", "r_other", "num_trees", "mean_speed", "median_speed", 
#                                      "mean_congestion", "median_congestion", "weatherstation", "station_distance", 
#                                      "station_elevation", "x", "y", "z", "temp_fahrenheit", "rel_humidity", 
#                                      "wind_direction", "wind_speed"),
#                                    c("Timestamp of the measurement", 
#                                      "PM2.5 concentration from the air sensor", 
#                                      "PM2.5 concentration from channel A of the air sensor", 
#                                      "PM2.5 concentration from channel B of the air sensor", 
#                                      "Unique identifier for the sensor", 
#                                      "Day of the week (1 = Sunday, 2 = Monday, ...)", 
#                                      "Hour of the day (0-23)", 
#                                      "Day of the month", 
#                                      "Month of the year", 
#                                      "Year of the measurement", 
#                                      "Weekend indicator (1 if weekend, 0 otherwise)", 
#                                      "Holiday indicator (1 if holiday, 0 otherwise)", 
#                                      "Total building area in square meters around the sensor", 
#                                      "Count of buildings classified as 'yes'", 
#                                      "Count of apartments", 
#                                      "Count of houses", 
#                                      "Count of buildings with NA classification", 
#                                      "Count of residential buildings", 
#                                      "Count of terrace buildings", 
#                                      "Count of other types of buildings", 
#                                      "Total length of roads in meters around the sensor", 
#                                      "Length of footways in meters around the sensor", 
#                                      "Length of residential roads in meters around the sensor", 
#                                      "Length of service roads in meters around the sensor", 
#                                      "Length of secondary roads in meters around the sensor", 
#                                      "Length of primary roads in meters around the sensor", 
#                                      "Length of tertiary roads in meters around the sensor", 
#                                      "Length of steps in meters around the sensor", 
#                                      "Length of paths in meters around the sensor", 
#                                      "Length of motorway links in meters around the sensor", 
#                                      "Length of other types of roads in meters around the sensor", 
#                                      "Number of trees around the sensor", 
#                                      "Mean speed of vehicles in mph", 
#                                      "Median speed of vehicles in mph", 
#                                      "Mean congestion ratio", 
#                                      "Median congestion ratio", 
#                                      "Weather station identifier", 
#                                      "Distance to the weather station in meters", 
#                                      "Elevation of the weather station in meters", 
#                                      "X-coordinate of the weather station", 
#                                      "Y-coordinate of the weather station", 
#                                      "Z-coordinate of the weather station", 
#                                      "Temperature in Fahrenheit", 
#                                      "Relative humidity in percentage", 
#                                      "Wind direction in degrees", 
#                                      "Wind speed in mph"))
# 
# # Print data dictionary
# print_data_dict(dataset, data_title="Final Dataset", descriptions=descriptions, show_na = FALSE)



data = dataset
var_types = list(
  categorical = c("sensor_index", "dow"),
  logical = c("holiday", "wknd")
)
include_stats = list(
  numeric = c("mean", "median")
)


generate_summary_stats(
  data = dataset,
  var_types = list(
    categorical = c("sensor_index", "dow"),
    logical = c("holiday", "wknd")
  ),
  include_stats = list(
    numeric = c("mean", "median", "hist")
  )
)



knitr::asis_output(output)
```

# Remove any unnecessary features
```{r, eval=FALSE}
dataset <- dataset %>% select(-pm1.0_atm,-pm2.5_atm_a,-pm2.5_atm_b,-sensor_id,-TemperatureCelsius,-time_stamp)
glimpse(dataset)
```

# Split Train and Test data
```{r, eval=FALSE}
suppressPackageStartupMessages({
  library(caTools)
})
set.seed(42)

# Define the time point at which to split the data (e.g., 70% for training)
split_time <- quantile(dataset$local_timestamp, 0.7)

# Split the data into training and testing sets based on the split_time
train_data <- subset(dataset, local_timestamp <= split_time)
test_data <- subset(dataset, local_timestamp > split_time)

train_data <- train_data %>% select(-local_timestamp)
test_data <- test_data %>% select(-local_timestamp)

# split <- sample.split(dataset$pm2.5_atm, SplitRatio = 0.7)
# train_data <- subset(dataset, split == TRUE)
# test_data  <- subset(dataset, split == FALSE)
```

# Random Forest Model

```{r, eval=FALSE}
# Train random forest model
suppressPackageStartupMessages({
  library(randomForest)
})
set.seed(42)
rf_model <- randomForest(pm2.5_atm ~ ., data = train_data, ntree = 500)

# Make random forest predictions
predictions_rf <- predict(rf_model, test_data)

# Mean Absolute Error

MAE <- mean(abs(predictions_rf - test_data$pm2.5_atm))

# Compute R squared

R2 <- 1 - sum((test_data$pm2.5_atm - predictions_rf)^2) / sum((test_data$pm2.5_atm - mean(test_data$pm2.5_atm))^2)

# Print R squared

cat("R squared:", R2)

# Visualize predictions

suppressPackageStartupMessages({
  library(ggplot2)
})

# plot(predictions_rf,test_data$pm2.5_atm)

ggplot(data = test_data, aes(x = pm2.5_atm, y = predictions_rf)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red") +  # Add a diagonal line for reference
  labs(x = "Actual PM2.5", y = "Predicted PM2.5") +
  ggtitle("Scatter Plot of Predicted vs. Actual PM2.5") +
  theme_minimal()
```

# Train XGBoost model
```{r, eval=FALSE}
suppressPackageStartupMessages({
  library(xgboost)
})
set.seed(42)
target_variable <- "pm2.5_atm"
predictor_variables <- setdiff(names(train_data), target_variable)

train_matrix <- xgb.DMatrix(data = as.matrix(train_data[, predictor_variables]), label = train_data[, target_variable])
test_matrix <- xgb.DMatrix(data = as.matrix(test_data[, predictor_variables]))

# Define XGBoost parameters
xgb_params <- list(
  objective = "reg:squarederror",  # For regression tasks
  eval_metric = "rmse",            # Root Mean Squared Error as the evaluation metric
  eta = 0.1,                       # Learning rate (adjust as needed)
  max_depth = 6,                   # Maximum depth of trees (adjust as needed)
  nrounds = 500,                   # Number of boosting rounds (adjust as needed)
  verbosity = 0                    # Set to 0 to suppress output
)

# Train the XGBoost model
xgb_model <- xgboost(data = train_matrix, params = xgb_params, nrounds = xgb_params$nrounds)

predictions_xgb <- predict(xgb_model, newdata = test_matrix)

# Calculate MAE
MAE <- mean(abs(predictions_xgb - test_data$pm2.5_atm))

# Calculate RMSE
RMSE <- sqrt(mean((predictions_xgb - test_data$pm2.5_atm)^2))

# Calculate R-squared (R²)
SSE <- sum((predictions_xgb - test_data$pm2.5_atm)^2)
SST <- sum((test_data$pm2.5_atm - mean(test_data$pm2.5_atm))^2)
R2 <- 1 - SSE / SST

cat("Mean Absolute Error (MAE):", MAE, "\n")
cat("Root Mean Squared Error (RMSE):", RMSE, "\n")
cat("R-squared (R²):", R2, "\n")

ggplot(data = test_data, aes(x = pm2.5_atm, y = predictions_xgb)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red") +  # Add a diagonal line for reference
  labs(x = "Actual PM2.5", y = "Predicted PM2.5") +
  ggtitle("Scatter Plot of Predicted vs. Actual PM2.5") +
  theme_minimal()
```

# XGBoost Feature importance
``` {r, eval=FALSE}
importance_scores <- xgb.importance(model = xgb_model)
xgb.plot.importance(importance_matrix = importance_scores)
```


# Investigate PM2.5 readings
``` {r, eval=FALSE}

hist_data <- hist(dataset$pm2.5_atm, breaks = 50, xlab = "PM2.5 Concentration", xaxt = 'n')
axis(side = 1, at = hist_data$mids, labels = hist_data$mids)

hist_table <- data.frame(
  Bin_Start = hist_data$breaks[-length(hist_data$breaks)],
  Bin_End = hist_data$breaks[-1],
  Frequency = hist_data$counts
)

# Print the histogram data as a table
print(hist_table)
```
