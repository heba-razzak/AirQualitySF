---
title: "Model Building"
output: github_document
---

```{r, testing, eval = FALSE, include = FALSE}
# preprocessing_directory <- paste0(readr::read_file("inputs/preprocessing_directory.txt"),"/test")
```

# Model Building

```{r setup, include=FALSE}
preprocessing_directory <- readr::read_file("inputs/preprocessing_directory.txt")
model_directory <- readr::read_file("inputs/model_directory.txt")
options(scipen = 999)
```

## Load required libraries
```{r, load-libraries, message = FALSE, warning = FALSE}
library(lubridate) # For dates
library(dplyr) # For data manipulation
library(sf) # For working with spatial data
library(mapview) # to view maps
library(tidyr) # pivot
library(ggplot2) # plots
library(data.table) # Faster than dataframes (for big files)
library(randomForest) # random forest model
library(xgboost)
library(mlr)
library(caTools) # Split train and test groups
library(car)
# devtools::install_github("heba-razzak/createDataDict")
# library(createDataDict)
```

```{r}
dataset <- fread(paste0(preprocessing_directory, "/final_dataset.csv"))
dataset <- dataset %>% rename(target = pm2.5_atm)
```

## Linear Regression

```{r}
# Linear Regression
dataset_lr <- dataset %>%
  select(-starts_with("mean_speed"),
         -starts_with("median_speed"),
         -starts_with("mean_congestion"),
         -starts_with("median_congestion"))

dataset_lr <- na.omit(dataset_lr)

dataset_lr <- dataset_lr %>% filter(target < 150)

# Determine the index for the 70% split
split_index <- floor(0.7 * nrow(arrange(dataset_lr, time_stamp)))

# Find the date at this index
split_time <- dataset_lr %>% arrange(time_stamp) %>%
  pull(time_stamp) %>% .[floor(0.7 * nrow(dataset_lr))]

# Split the data into training and testing sets based on the split_time
train <- subset(dataset_lr, time_stamp <= split_time) %>% dplyr::select(-time_stamp, -sensor_index)
test <- subset(dataset_lr, time_stamp > split_time)

# Save timestamp and sensor index for identifying problem areas
test_time_sensor <- test %>% select(time_stamp, sensor_index)

# Remove timestamp and sensor index from test set for model training
test <- test %>% dplyr::select(-time_stamp, -sensor_index)

# True labels for test data
test_label <- test$target

# Drop target column from test
test <- test %>% dplyr::select(-target)

# Linear Regression Model
linear_model <- lm(target ~ ., data = train)

# Multicollinearity
vif_values <- vif(linear_model)
print("Variance Inflation Factors")
print(vif_values)
cat("--------------------------------------------------------------")

# Summarize the model
print("Model Summary")
summary(linear_model)
cat("--------------------------------------------------------------")

# Make predictions
linear_predictions <- predict(linear_model, newdata = test)

# Calculate performance metrics
# Mean Absolute Error (MAE)
mae_linear <- mean(abs(linear_predictions - test_label))
cat("\nLinear Regression MAE:", mae_linear)

# Mean Absolute Percentage Error (MAPE)
# Replace zero values in test_label with a very small number
mape_test_label <- ifelse(test_label == 0, 0.00001, test_label)

# Calculate Mean Absolute Percentage Error (MAPE)
mape_linear <- mean(abs((linear_predictions - mape_test_label) / mape_test_label)) * 100
cat("\nLinear Regression MAPE:", mape_linear)

# R-squared (R²)
ss_res_linear <- sum((linear_predictions - test_label)^2)
ss_tot_linear <- sum((test_label - mean(test_label))^2)
r2_linear <- 1 - (ss_res_linear / ss_tot_linear)
cat("\nLinear Regression R²:", r2_linear)

# Adjusted R-squared
n_linear <- length(test_label)
p_linear <- ncol(test)
adj_r2_linear <- 1 - ((1 - r2_linear) * (n_linear - 1) / (n_linear - p_linear - 1))
cat("\nLinear Regression Adjusted R²:", adj_r2_linear)

# Root Mean Squared Error (RMSE)
rmse_linear <- sqrt(mean((linear_predictions - test_label)^2))
cat("\nLinear Regression RMSE:", rmse_linear, "\n")

# Create a dataframe with actual values, predicted values, absolute differences, and identification columns
results <- test %>%
  mutate(
    Actual = test_label,
    Predicted = linear_predictions,
    AbsDifference = abs(test_label - linear_predictions)
  ) %>%
  bind_cols(test_time_sensor) %>% 
  arrange(desc(AbsDifference))

# Plot to show which days have the most errors
error_by_day <- results %>%
  mutate(date = as.Date(time_stamp)) %>%
  group_by(date) %>%
  summarize(TotalAbsDifference = sum(AbsDifference),
            AvgAbsDifference = mean(AbsDifference),
            MaxAbsDifference = max(AbsDifference),
            AbsDifference90p = quantile(AbsDifference, 0.9)) %>%
  arrange(date)

# Plot average, maximum, and 90th percentile absolute differences
ggplot(error_by_day, aes(x = date)) +
  geom_line(aes(y = AvgAbsDifference, color = "Average Absolute Difference")) +
  geom_line(aes(y = MaxAbsDifference, color = "Maximum Absolute Difference")) +
  geom_line(aes(y = AbsDifference90p, color = "90th Percentile Absolute Difference")) +
  labs(
    title = "Absolute Differences Over Time",
    x = "Date",
    y = "Absolute Difference"
  ) +
  scale_color_manual(
    values = c("Average Absolute Difference" = "blue",
               "Maximum Absolute Difference" = "red",
               "90th Percentile Absolute Difference" = "green")
  ) +
  theme_minimal()

# Display the sorted results
print(error_by_day)


# Plot residuals
residuals <- test_label - linear_predictions
plot(residuals, main = "Residuals Plot", ylab = "Residuals", xlab = "Index", col = "blue", pch = 20)
abline(h = 0, col = "red")

# Histogram of residuals
hist(residuals, breaks = 50, main = "Histogram of Residuals", xlab = "Residuals", col = "blue")

# Plot predictions vs actual values
plot(test_label, linear_predictions, main = "Predictions vs Actual Values", xlab = "Actual Values", ylab = "Predicted Values", col = "blue", pch = 19)
abline(0, 1, col = "red")
```

## Log Linear Regression

```{r}
# Log Linear Regression
dataset_loglr <- dataset %>%
  select(-starts_with("mean_speed"),
         -starts_with("median_speed"),
         -starts_with("mean_congestion"),
         -starts_with("median_congestion"))

dataset_loglr <- na.omit(dataset_loglr)

dataset_loglr <- dataset_loglr %>% filter(target < 150)

# Determine the index for the 70% split
split_index <- floor(0.7 * nrow(arrange(dataset_loglr, time_stamp)))

# Find the date at this index
split_time <- dataset_loglr %>% arrange(time_stamp) %>%
  pull(time_stamp) %>% .[split_index]

# Split the data into training and testing sets based on the split_time
train <- subset(dataset_loglr, time_stamp <= split_time) %>% dplyr::select(-time_stamp, -sensor_index)
test <- subset(dataset_loglr, time_stamp > split_time)

# Save timestamp and sensor index for identifying problem areas
test_time_sensor <- test %>% select(time_stamp, sensor_index)

# Remove timestamp and sensor index from test set for model training
test <- test %>% dplyr::select(-time_stamp, -sensor_index)

# True labels for test data
test_label <- test$target

# Drop target column from test
test <- test %>% dplyr::select(-target)

# Log linear Regression Model
loglr_model <- lm(log(1 + target) ~ ., data = train)

# Multicollinearity
vif_values <- vif(loglr_model)
print("Variance Inflation Factors")
print(vif_values)
cat("--------------------------------------------------------------")

# Summarize the model
print("Model Summary")
summary(loglr_model)
cat("--------------------------------------------------------------")

# Make log linear predictions
loglr_predictions <- exp(predict(loglr_model, newdata = test) - 1)

# Calculate performance metrics
# Mean Absolute Error (MAE)
mae_loglr <- mean(abs(loglr_predictions - test_label))
cat("\nLog Linear Regression MAE:", mae_loglr)

# Mean Absolute Percentage Error (MAPE)
# Replace zero values in test_label with a very small number
mape_test_label <- ifelse(test_label == 0, 0.00001, test_label)
mape_loglr <- mean(abs((loglr_predictions - mape_test_label) / mape_test_label)) * 100
cat("\nLog Linear Regression MAPE:", mape_loglr)

# R-squared (R²)
ss_res_loglr <- sum((loglr_predictions - test_label)^2)
ss_tot_loglr <- sum((test_label - mean(test_label))^2)
r2_loglr <- 1 - (ss_res_loglr / ss_tot_loglr)
cat("\nLog Linear Regression R²:", r2_loglr)

# Adjusted R-squared
n_loglr <- length(test_label)
p_loglr <- ncol(test)
adj_r2_loglr <- 1 - ((1 - r2_loglr) * (n_loglr - 1) / (n_loglr - p_loglr - 1))
cat("\nLog Linear Regression Adjusted R²:", adj_r2_loglr)

# Root Mean Squared Error (RMSE)
rmse_loglr <- sqrt(mean((loglr_predictions - test_label)^2))
cat("\nLog Linear Regression RMSE:", rmse_loglr, "\n")

# Create a dataframe with actual values, predicted values, absolute differences, and identification columns
results <- test %>%
  mutate(
    Actual = test_label,
    Predicted = loglr_predictions,
    AbsDifference = abs(test_label - loglr_predictions)
  ) %>%
  bind_cols(test_time_sensor) %>% 
  arrange(desc(AbsDifference))

# Plot to show which days have the most errors
error_by_day <- results %>%
  mutate(date = as.Date(time_stamp)) %>%
  group_by(date) %>%
  summarize(TotalAbsDifference = sum(AbsDifference),
            AvgAbsDifference = mean(AbsDifference),
            MedianAbsDifference = quantile(AbsDifference, 0.5),
            MaxAbsDifference = max(AbsDifference),
            AbsDifference90p = quantile(AbsDifference, 0.9)) %>%
  arrange(date)

# Plot average, maximum, and 90th percentile absolute differences
ggplot(error_by_day, aes(x = date)) +
  geom_line(aes(y = AvgAbsDifference, color = "Average Absolute Difference")) +
  geom_line(aes(y = MaxAbsDifference, color = "Maximum Absolute Difference")) +
  geom_line(aes(y = AbsDifference90p, color = "90th Percentile Absolute Difference")) +
  labs(
    title = "Absolute Differences Over Time",
    x = "Date",
    y = "Absolute Difference"
  ) +
  scale_color_manual(
    values = c("Average Absolute Difference" = "blue",
               "Maximum Absolute Difference" = "red",
               "90th Percentile Absolute Difference" = "green")
  ) +
  theme_minimal()

# Display the sorted results
print(error_by_day)

# Plot residuals
cat("Plotting residuals\n")
residuals <- test_label - loglr_predictions
plot(residuals, main = "Residuals Plot", ylab = "Residuals", xlab = "Index", col = "blue", pch = 20)
abline(h = 0, col = "red")

# Histogram of residuals
hist(residuals, breaks = 50, main = "Histogram of Residuals", xlab = "Residuals", col = "blue")

# Plot predictions vs actual values
plot(test_label, loglr_predictions, main = "Predictions vs Actual Values", xlab = "Actual Values", ylab = "Predicted Values", col = "blue", pch = 19)
abline(0, 1, col = "red")

```

```{}
plot(linear_model)

```


# XGBOOST

```{}
dataset <- fread(paste0(preprocessing_directory, "/final_dataset.csv"))
dataset <- dataset %>% rename(target = pm2.5_atm)
```

```{r, eval = FALSE}
# Transform dataset and save
dataset_xgb <- dataset %>%
  mutate(year = year - min(year))

saveRDS(dataset_xgb, file = paste0(model_directory, "/dataset_xgb.rds"))

```

```{r, eval = FALSE}
# Load transformed dataset
dataset_xgb <- readRDS(paste0(model_directory, "/dataset_xgb.rds"))

# Determine the index for the 70% split
split_index <- floor(0.7 * nrow(arrange(dataset_xgb, time_stamp)))

# Find the date at this index
split_time <- dataset_xgb %>% arrange(time_stamp) %>%
  pull(time_stamp) %>% .[split_index]

# Split the data into training and testing sets based on the split_time
train <- subset(dataset_xgb, time_stamp <= split_time)
test <- subset(dataset_xgb, time_stamp > split_time)

# Remove timestamp and sensor index from the features
train <- train %>% select(-time_stamp, -sensor_index)
test <- test %>% select(-time_stamp, -sensor_index)

# Save split datasets
saveRDS(dataset_xgb, file = paste0(model_directory, "/train.rds"))
saveRDS(dataset_xgb, file = paste0(model_directory, "/test.rds"))

train %>% filter(is.na(year))
test %>% filter(is.na(year))
```

```{r}
# Load split datasets
train <- readRDS(paste0(model_directory, "/train.rds"))
test <- readRDS(paste0(model_directory, "/test.rds"))

# Extract labels
train_labels <- train$log_target
test_labels <- test$log_target

# Remove log_target from features
train_matrix <- as.matrix(train %>% select(-log_target))
test_matrix <- as.matrix(test %>% select(-log_target))

# Save matrices and labels
saveRDS(dataset_xgb, file = paste0(model_directory, "/train_matrix.rds"))
saveRDS(dataset_xgb, file = paste0(model_directory, "/test_matrix.rds"))
saveRDS(dataset_xgb, file = paste0(model_directory, "/train_labels.rds"))
saveRDS(dataset_xgb, file = paste0(model_directory, "/test_labels.rds"))
```

```{r}
# Load matrices and labels
train_matrix <- readRDS(paste0(model_directory, "/train_matrix.rds"))
test_matrix <- readRDS(paste0(model_directory, "/test_matrix.rds"))
train_labels <- readRDS(paste0(model_directory, "/train_labels.rds"))
test_labels <- readRDS(paste0(model_directory, "/test_labels.rds"))

# Scale data (optional, depends on the data)
train_matrix <- scale(train_matrix)
test_matrix <- scale(test_matrix)

# Create DMatrix objects
dtrain <- xgb.DMatrix(data = train_matrix, label = train_labels)
dtest <- xgb.DMatrix(data = test_matrix, label = test_labels)

saveRDS(dataset_xgb, file = paste0(model_directory, "/dtrain.rds"))
saveRDS(dataset_xgb, file = paste0(model_directory, "/dtest.rds"))
```

```{r}
# Load DMatrix objects
dtrain <- readRDS(paste0(model_directory, "/dtrain.rds"))
dtest <- readRDS(paste0(model_directory, "/dtest.rds"))

print("Initial Cross-Validation")

# Initial cross-validation to find the best number of rounds
params <- list(
  booster = "gbtree",
  objective = "reg:squarederror",
  eta = 0.1,
  gamma = 0,
  max_depth = 6,
  min_child_weight = 1,
  subsample = 1,
  colsample_bytree = 1
)

xgbcv <- xgb.cv(
  params = params,
  data = dtrain,
  nrounds = 100,
  nfold = 5,
  showsd = TRUE,
  stratified = FALSE,
  print_every_n = 10,
  early_stopping_rounds = 20,
  maximize = FALSE
)

saveRDS(dataset_xgb, file = paste0(model_directory, "/xgbcv.rds"))

print("Cross-validation completed")
print(xgbcv$evaluation_log)

best_nrounds <- xgbcv$best_iteration
print(paste("Best number of rounds:", best_nrounds))

print("Hyperparameter Tuning with MLR")

# Create tasks
traintask <- makeRegrTask(data = as.data.frame(train_matrix), target = "log_target")
testtask <- makeRegrTask(data = as.data.frame(test_matrix), target = "log_target")

# Save tasks
saveRDS(dataset_xgb, file = paste0(model_directory, "/traintask.rds"))
saveRDS(dataset_xgb, file = paste0(model_directory, "/testtask.rds"))
```

```{r}
# Load tasks
traintask <- readRDS(paste0(model_directory, "/traintask.rds"))
testtask <- readRDS(paste0(model_directory, "/testtask.rds"))

# Create learner
lrn <- makeLearner("regr.xgboost", predict.type = "response")
lrn$par.vals <- list(objective = "reg:squarederror", eval_metric = "rmse", nrounds = best_nrounds)

# Set parameter space
params <- makeParamSet(
  makeDiscreteParam("booster", values = c("gbtree", "gblinear")),
  makeIntegerParam("max_depth", lower = 3L, upper = 10L),
  makeNumericParam("min_child_weight", lower = 1L, upper = 10L),
  makeNumericParam("subsample", lower = 0.5, upper = 1),
  makeNumericParam("colsample_bytree", lower = 0.5, upper = 1)
)

# Set resampling strategy
rdesc <- makeResampleDesc("CV", stratify = FALSE, iters = 5L)

# Search strategy
ctrl <- makeTuneControlRandom(maxit = 10L)

# Parameter tuning
print("Starting parameter tuning")
mytune <- tuneParams(
  learner = lrn,
  task = traintask,
  resampling = rdesc,
  par.set = params,
  control = ctrl,
  show.info = TRUE
)

saveRDS(dataset_xgb, file = paste0(model_directory, "/mytune.rds"))

print("Parameter tuning completed")
print(mytune)

# Set hyperparameters
lrn_tune <- setHyperPars(lrn, par.vals = mytune$x)

# Train model
print("Training final model")
xgmodel <- mlr::train(learner = lrn_tune, task = traintask)

saveRDS(dataset_xgb, file = paste0(model_directory, "/xgmodel.rds"))

# Predict model
print("Making predictions on test set")
xgpred <- predict(xgmodel, testtask)

saveRDS(dataset_xgb, file = paste0(model_directory, "/xgpred.rds"))
```

```{r}
# Load trained model and predictions
# xgmodel <- readRDS("xgmodel.rds"))
# xgpred <- readRDS("xgpred.rds"))

# Transform predictions and actual values back to the original scale
xgbpred_original <- expm1(xgpred$data$response)
test_labels_original <- expm1(test_labels)

# Calculate performance metrics on the original scale
rmse_original <- sqrt(mean((xgbpred_original - test_labels_original)^2))
print(paste("RMSE on original scale:", rmse_original))

# Calculate R-squared on the original scale
rss <- sum((xgbpred_original - test_labels_original)^2)
tss <- sum((test_labels_original - mean(test_labels_original))^2)
r_squared <- 1 - (rss / tss)
print(paste("R-squared on original scale:", r_squared))

# Calculate Adjusted R-squared on the original scale
n <- length(test_labels_original)
p <- ncol(test_matrix)
adjusted_r_squared <- 1 - ((1 - r_squared) * (n - 1) / (n - p - 1))
print(paste("Adjusted R-squared on original scale:", adjusted_r_squared))

# Plot residuals
print("Plotting residuals")
residuals <- test_labels_original - xgbpred_original
plot(residuals, main = "Residuals Plot", ylab = "Residuals", xlab = "Index", col = "blue", pch = 20)
abline(h = 0, col = "red")

# Histogram of residuals
hist(residuals, breaks = 50, main = "Histogram of Residuals", xlab = "Residuals", col = "blue")

# Plot predictions vs actual values
plot(test_labels_original, xgbpred_original, main = "Predictions vs Actual Values", xlab = "Actual Values", ylab = "Predicted Values", col = "blue", pch = 19)
abline(0, 1, col = "red")


```


```{r}
# # Compare with XGBoost performance
# print(paste("XGBoost RMSE:", rmse_xgb), rmse_linear)
# print(paste("XGBoost MAE:", mae_xgb), mae_linear)
# print(paste("XGBoost MAPE:", mape_xgb), mape_linear)
# print(paste("XGBoost R²:", r2_xgb), r2_linear)
# print(paste("XGBoost Adjusted R²:", adj_r2_xgb), adj_r2_linear)


```
































```{r}
dataset_xgb <- dataset %>%
  mutate(log_target = log1p(target)) %>%
  select(-starts_with("mean_speed"),
         -starts_with("median_speed"),
         -starts_with("mean_congestion"),
         -starts_with("median_congestion"),
         -z, -target)

# Determine the index for the 70% split
split_index <- floor(0.7 * nrow(arrange(dataset_xgb, time_stamp)))

# Find the date at this index
split_time <- dataset_xgb %>% arrange(time_stamp) %>%
  pull(time_stamp) %>% .[floor(0.7 * nrow(dataset_xgb))]

# Split the data into training and testing sets based on the split_time
train <- subset(dataset_xgb, time_stamp <= split_time)
test <- subset(dataset_xgb, time_stamp > split_time)

# remove timestamp and sensor index
train <- train %>% select(-time_stamp, -sensor_index)
test <- test %>% select(-time_stamp, -sensor_index)

# Convert data to matrix format for xgboost
train_matrix <- as.matrix(train %>% select(-log_target))
test_matrix <- as.matrix(test %>% select(-log_target))

# Extract labels
train_labels <- train$log_target
test_labels <- test$log_target

# Create DMatrix objects
dtrain <- xgb.DMatrix(data = train_matrix, label = train_labels)
dtest <- xgb.DMatrix(data = test_matrix, label = test_labels)

# Update training and testing matrices
train_matrix <- as.matrix(train %>% select(-log_target))
test_matrix <- as.matrix(test %>% select(-log_target))

# scale data
train_matrix <- scale(train_matrix)
test_matrix <- scale(test_matrix)
```


```{r}
params <- list(
  booster = "gbtree",
  objective = "reg:squarederror",
  eta = 0.1,
  gamma = 0,
  max_depth = 6,
  min_child_weight = 1,
  subsample = 1,
  colsample_bytree = 1
)

# Cross-validation with reduced number of rounds and early stopping
xgbcv <- xgb.cv(
  params = params,
  data = dtrain,
  nrounds = 100,
  nfold = 5,
  showsd = TRUE,
  stratified = FALSE,
  print_every_n = 10,
  early_stopping_rounds = 20,
  maximize = FALSE
)

# Print the evaluation log to see the performance
print(xgbcv$evaluation_log)
```

```{r}
# Train the model
# Get the best number of iterations
best_nrounds <- xgbcv$best_iteration
print(paste("Best number of rounds:", best_nrounds))

# Train the model with the best number of rounds
xgb1 <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = best_nrounds,
  watchlist = list(val = dtest, train = dtrain),
  print_every_n = 10,
  early_stopping_rounds = 10,
  maximize = FALSE,
  eval_metric = "rmse"
)

# Model prediction
xgbpred <- predict(xgb1, dtest)

# Calculate performance metrics
rmse <- sqrt(mean((xgbpred - test_labels)^2))
print(paste("RMSE:", rmse))

# Extract feature importance
mat <- xgb.importance(feature_names = colnames(train_matrix), model = xgb1)
xgb.plot.importance(importance_matrix = mat[1:20])
```

```{r}
# Create tasks
traintask <- makeRegrTask(data = train, target = "log_target")
testtask <- makeRegrTask(data = test, target = "log_target")

# Create learner
lrn <- makeLearner("regr.xgboost", predict.type = "response")
lrn$par.vals <- list(objective = "reg:squarederror",
                     eval_metric = "rmse", nrounds = 100L,
                     # print_every_n = 10, 
                     eta = 0.1)

# Set parameter space
params <- makeParamSet(
  makeDiscreteParam("booster", values = c("gbtree", "gblinear")),
  makeIntegerParam("max_depth", lower = 3L, upper = 10L),
  makeNumericParam("min_child_weight", lower = 1L, upper = 10L),
  makeNumericParam("subsample", lower = 0.5, upper = 1),
  makeNumericParam("colsample_bytree", lower = 0.5, upper = 1)
)

# Set resampling strategy
rdesc <- makeResampleDesc("CV", stratify = FALSE, iters = 5L)

# Search strategy
ctrl <- makeTuneControlRandom(maxit = 10L)

# Parameter tuning
mytune <- tuneParams(
  learner = lrn,
  task = traintask, 
  resampling = rdesc, 
  # measures = acc, 
  par.set = params, 
  control = ctrl, 
  show.info = T)

mytune$y

# Set hyperparameters
lrn_tune <- setHyperPars(lrn, par.vals = mytune$x)

# Train model
xgmodel <- mlr::train(learner = lrn_tune, task = traintask)

# Predict model
xgpred <- predict(xgmodel, testtask)

# Calculate performance metrics
final_rmse <- sqrt(mean((xgpred$data$response - xgpred$data$truth)^2))
print(paste("RMSE:", final_rmse))

# Calculate Residual Sum of Squares (RSS)
rss <- sum((xgpred$data$response - test_labels)^2)

# Calculate Total Sum of Squares (TSS)
tss <- sum((test_labels - mean(test_labels))^2)

# Calculate R-squared
r_squared <- 1 - (rss / tss)
print(paste("R-squared:", r_squared))

# Calculate Adjusted R-squared
n <- length(test_labels)  # Number of observations
p <- ncol(test_matrix)    # Number of predictors

adjusted_r_squared <- 1 - ((1 - r_squared) * (n - 1) / (n - p - 1))
print(paste("Adjusted R-squared:", adjusted_r_squared))
```

```{r}
# Transform predictions and actual values back to the original scale
xgbpred_original <- expm1(xgbpred)
test_labels_original <- expm1(test_labels)

# Calculate performance metrics on the original scale
rmse_original <- sqrt(mean((xgbpred_original - test_labels_original)^2))
print(paste("RMSE on original scale:", rmse_original))

# Calculate Residual Sum of Squares (RSS) on the original scale
rss_original <- sum((xgbpred_original - test_labels_original)^2)

# Calculate Total Sum of Squares (TSS) on the original scale
tss_original <- sum((test_labels_original - mean(test_labels_original))^2)

# Calculate R-squared on the original scale
r_squared_original <- 1 - (rss_original / tss_original)
print(paste("R-squared on original scale:", r_squared_original))

# Calculate Adjusted R-squared on the original scale
n <- length(test_labels_original)  # Number of observations
p <- ncol(test_matrix)    # Number of predictors

adjusted_r_squared_original <- 1 - ((1 - r_squared_original) * (n - 1) / (n - p - 1))
print(paste("Adjusted R-squared on original scale:", adjusted_r_squared_original))



```


```{r}

# Calculate residuals
residuals <- test_labels - xgbpred

# Plot residuals
plot(residuals, main = "Residuals Plot", ylab = "Residuals", xlab = "Index", col = "blue", pch = 20)
abline(h = 0, col = "red")

# Histogram of residuals
hist(residuals, breaks = 50, main = "Histogram of Residuals", xlab = "Residuals", col = "blue")

```

```{r}
# Transform predictions and actual values back to the original scale
xgbpred_original <- expm1(xgbpred)
test_labels_original <- expm1(test_labels)

# Plot predictions vs actual values
plot(test_labels_original, xgbpred_original, 
     main = "Predictions vs Actual Values", 
     xlab = "Actual Values", ylab = "Predicted Values", 
     col = "blue", pch = 19)
abline(0, 1, col = "red")

```













## Data Dictionary

```{r}
# # View initial data dictionary
# print_data_dict(dataset)

# get dataframe for descriptions
descriptions <- descriptions_df(dataset)
# Update descriptions dataframe
descriptions <- update_description(descriptions,
                                   c("time_stamp", "target", "sensor_index", "dow", "hour",
                                     "day", "month", "year", "wknd", "holiday", 
                                     "length_major", "length_minor", "mean_speed_minor", 
                                     "mean_speed_major", "median_speed_minor", "median_speed_major",
                                     "mean_congestion_minor", "mean_congestion_major", 
                                     "median_congestion_minor", "median_congestion_major",
                                     "weatherstation", "station_distance", "station_elevation", 
                                     "x", "y", "z", "temp_fahrenheit", "rel_humidity", 
                                     "wind_direction", "wind_speed", "area_house", 
                                     "area_other", "area_apartments", "num_trees"),
                                   c("Timestamp of the measurement",
                                     "PM2.5 concentration",
                                     "Unique identifier for sensors",
                                     "Day of the week (1 = Sunday, 2 = Monday, ...)",
                                     "Hour of the day (0-23)",
                                     "Day of the month",
                                     "Month of the year",
                                     "Year of the measurement",
                                     "Weekend indicator (1 if weekend, 0 otherwise)",
                                     "Holiday indicator (1 if holiday, 0 otherwise)",
                                     "Total length of major roads (m)",
                                     "Total length of minor roads (m)",
                                     "Mean speed on minor roads (mph)",
                                     "Mean speed on major roads (mph)",
                                     "Median speed on minor roads (mph)",
                                     "Median speed on major roads (mph)",
                                     "Mean congestion ratio on minor roads",
                                     "Mean congestion ratio on major roads",
                                     "Median congestion ratio on minor roads",
                                     "Median congestion ratio on major roads",
                                     "Weather station identifier",
                                     "Distance to the weather station in meters",
                                     "Elevation of the weather station in meters",
                                     "X-coordinate of the sensor in Cartesian coordinates",
                                     "Y-coordinate of the sensor in Cartesian coordinates",
                                     "Z-coordinate of the sensor in Cartesian coordinates",
                                     "Temperature in Fahrenheit",
                                     "Relative humidity in percentage",
                                     "Wind direction in degrees",
                                     "Wind speed (mph)",
                                     "Total area of houses (m^2)",
                                     "Total area of other buildings (m^2)",
                                     "Total area of apartments (m^2)",
                                     "Number of trees around sensor"))


```

```{r}
# Print data dictionary
print_data_dict(dataset, data_title="Final Dataset", descriptions=descriptions, show_na = TRUE)
```

```{r}
# data = dataset
# var_types = list(
#   categorical = c("sensor_index", "dow"),
#   logical = c("holiday", "wknd")
# )
# include_stats = list(
#   numeric = c("mean", "median")
# )


# generate_summary_stats(
#   data = dataset,
#   var_types = list(
#     categorical = c("sensor_index", "dow"),
#     logical = c("holiday", "wknd")
#   ),
#   include_stats = list(
#     numeric = c("mean", "median", "hist")
#   )
# )



# knitr::asis_output(output)
```


```{r, view-data}

dataset
```

# Remove any unnecessary features
```{r, eval=TRUE}
# drop after splitting
# dataset <- dataset %>% select(-time_stamp, -sensor_index)
dataset <- dataset %>%
  select(-starts_with("mean_speed"),
         -starts_with("median_speed"),
         -starts_with("mean_congestion"),
         -starts_with("median_congestion"))

dataset <- na.omit(dataset)
```

```{r}
# Print data dictionary
print_data_dict(dataset, data_title="Final Dataset", show_na = TRUE)
```


```{r}
library(ggplot2)
library(MASS)
library(caret)


# preprocessing_directory <- readr::read_file("inputs/preprocessing_directory.txt")
# preprocessing_directory <- paste0(readr::read_file("inputs/preprocessing_directory.txt"),"/test")
# dataset <- fread(paste0(preprocessing_directory, "/final_dataset.csv"))

# Define the variable to transform
variable <- "target"

# Function to create histograms and Q-Q plots
plot_transformations <- function(data, variable, transformed_data, transformation_name) {
  p1 <- ggplot(data, aes_string(x = variable)) + 
    geom_histogram(binwidth = 1, fill = "steelblue", color = "black") + 
    theme_minimal() + 
    labs(title = paste("Histogram of", transformation_name, "Transformation"), x = transformation_name, y = "Frequency")
  
  p2 <- ggplot(data, aes_string(sample = transformed_data)) + 
    stat_qq() + 
    stat_qq_line() + 
    theme_minimal() + 
    labs(title = paste("Q-Q Plot of", transformation_name, "Transformation"))
  
  gridExtra::grid.arrange(p1, p2, ncol = 2)
}

# Original Data
dataset$original <- dataset[[variable]]
plot_transformations(dataset, "original", "original", "Original Data")

# Log Transformation
dataset$log_transformed <- log(dataset[[variable]] + 1) # Adding 1 to avoid log(0)
plot_transformations(dataset, "log_transformed", "log_transformed", "Log")

# Reciprocal Transformation
dataset$reciprocal_transformed <- 1 / (dataset[[variable]] + 1) # Adding 1 to avoid division by 0
plot_transformations(dataset, "reciprocal_transformed", "reciprocal_transformed", "Reciprocal")

# Square Transformation
dataset$square_transformed <- dataset[[variable]]^2
plot_transformations(dataset, "square_transformed", "square_transformed", "Square")

# Square Root Transformation
dataset$sqrt_transformed <- sqrt(dataset[[variable]])
plot_transformations(dataset, "sqrt_transformed", "sqrt_transformed", "Square Root")

# Box-Cox Transformation
box_cox_trans <- boxcox(as.formula(paste(variable, "~ 1")), data = dataset)
lambda <- box_cox_trans$x[which.max(box_cox_trans$y)]
dataset$boxcox_transformed <- (dataset[[variable]]^lambda - 1) / lambda
plot_transformations(dataset, "boxcox_transformed", "boxcox_transformed", "Box-Cox")

# Yeo-Johnson Transformation
preProcValues <- preProcess(dataset[, .(variable)], method = "YeoJohnson")
dataset$yeojohnson_transformed <- predict(preProcValues, dataset[, .(variable)])
plot_transformations(dataset, "yeojohnson_transformed", "yeojohnson_transformed", "Yeo-Johnson")


```



# Split Train and Test data
```{r, eval=FALSE}

set.seed(42)

# First, order the data by time_stamp
ordered_data <- dataset %>% arrange(time_stamp)

# Determine the index for the 70% split
split_index <- floor(0.7 * nrow(ordered_data))

# Find the date at this index
split_time <- ordered_data$time_stamp[split_index]


# Split the data into training and testing sets based on the split_time
train <- subset(dataset, time_stamp <= split_time)
test <- subset(dataset, time_stamp > split_time)

# remove timestamp and sensor index
train <- train %>% select(-time_stamp, -sensor_index)
test <- test %>% select(-time_stamp, -sensor_index)

rm(ordered_data)
rm(dataset)
```

# XGBOOST
# XGBOOST
# XGBOOST
# XGBOOST
# XGBOOST
# XGBOOST

```{r}
library(data.table)
library(mlr)
library(xgboost)
library(Matrix)
library(data.table)
library(dplyr)
library(caret)

# Convert data frame to data table
setDT(train)
setDT(test)

# Identify non-numeric and numeric columns
non_numeric_cols <- names(train)[!sapply(train, is.numeric)]
numeric_cols <- names(train)[sapply(train, is.numeric)]

# Set missing values as "Missing" for non-numeric columns
train[, (non_numeric_cols) := lapply(.SD, function(x) ifelse(is.na(x), "Missing", x)), .SDcols = non_numeric_cols]
test[, (non_numeric_cols) := lapply(.SD, function(x) ifelse(is.na(x), "Missing", x)), .SDcols = non_numeric_cols]

# Set missing values as -1 for numeric columns
train[, (numeric_cols) := lapply(.SD, function(x) ifelse(is.na(x), -1, x)), .SDcols = numeric_cols]
test[, (numeric_cols) := lapply(.SD, function(x) ifelse(is.na(x), -1, x)), .SDcols = numeric_cols]

# One hot encoding
labels <- train$target
ts_label <- test$target
new_tr <- model.matrix(~ . + 0, data = train[, -c("target"), with = FALSE])
new_ts <- model.matrix(~ . + 0, data = test[, -c("target"), with = FALSE])

# Check if the number of rows in new_tr and new_ts matches the length of labels and ts_label
print(paste("Number of rows in new_tr:", nrow(new_tr)))
print(paste("Length of labels:", length(labels)))
print(paste("Number of rows in new_ts:", nrow(new_ts)))
print(paste("Length of ts_label:", length(ts_label)))

# Convert data to numeric
labels <- as.numeric(labels)
ts_label <- as.numeric(ts_label)

# Convert data to DMatrix
dtrain <- xgb.DMatrix(data = new_tr, label = labels)
dtest <- xgb.DMatrix(data = new_ts, label = ts_label)

# Define parameters for XGBoost
params <- list(
  booster = "gbtree",
  objective = "reg:squarederror",
  eta = 0.1,
  gamma = 0,
  max_depth = 6,
  min_child_weight = 1,
  subsample = 1,
  colsample_bytree = 1
)

# Cross-validation
xgbcv <- xgb.cv(
  params = params,
  data = dtrain,
  nrounds = 100,
  nfold = 5,
  showsd = TRUE,
  stratified = FALSE,
  print_every_n = 10,
  early_stopping_rounds = 20,
  maximize = FALSE
)

# Train the model
best_nrounds <- xgbcv$best_iteration
xgb1 <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = best_nrounds,
  watchlist = list(val = dtest, train = dtrain),
  print_every_n = 10,
  early_stopping_rounds = 10,
  maximize = FALSE,
  eval_metric = "rmse"
)

# Model prediction
xgbpred <- predict(xgb1, dtest)

# Calculate performance metrics
rmse <- sqrt(mean((xgbpred - ts_label)^2))
print(paste("RMSE:", rmse))

# Extract feature importance
mat <- xgb.importance(feature_names = colnames(new_tr), model = xgb1)
xgb.plot.importance(importance_matrix = mat[1:20])

# Convert characters to factors
fact_col <- colnames(train)[sapply(train, is.character)]
for (i in fact_col) set(train, j = i, value = factor(train[[i]]))
for (i in fact_col) set(test, j = i, value = factor(test[[i]]))

# Create tasks
traintask <- makeRegrTask(data = train, target = "target")
testtask <- makeRegrTask(data = test, target = "target")

# Do one hot encoding
traintask <- createDummyFeatures(obj = traintask, target = "target")
testtask <- createDummyFeatures(obj = testtask, target = "target")

# Create learner
lrn <- makeLearner("regr.xgboost", predict.type = "response")
lrn$par.vals <- list(objective = "reg:squarederror", eval_metric = "rmse", nrounds = 100L, eta = 0.1)

# Set parameter space
params <- makeParamSet(
  makeDiscreteParam("booster", values = c("gbtree", "gblinear")),
  makeIntegerParam("max_depth", lower = 3L, upper = 10L),
  makeNumericParam("min_child_weight", lower = 1L, upper = 10L),
  makeNumericParam("subsample", lower = 0.5, upper = 1),
  makeNumericParam("colsample_bytree", lower = 0.5, upper = 1)
)

# Set resampling strategy
rdesc <- makeResampleDesc("CV", stratify = FALSE, iters = 5L)

# Search strategy
ctrl <- makeTuneControlRandom(maxit = 10L)

# # Set parallel backend
# library(parallel)
# library(parallelMap)
# parallelStartSocket(cpus = detectCores())

# Parameter tuning
mytune <- tuneParams(
  learner = lrn,
  task = traintask, 
  resampling = rdesc, 
  measures = acc, 
  par.set = params, 
  control = ctrl, 
  show.info = T)
# mytune <- tuneParams(
#   learner = lrn,
#   task = traintask,
#   resampling = rdesc,
#   measures = rmse,
#   par.set = params,
#   control = ctrl,
#   show.info = TRUE
# )
mytune$y

# Set hyperparameters
lrn_tune <- setHyperPars(lrn, par.vals = mytune$x)

# Train model
xgmodel <- train(learner = lrn_tune, task = traintask)

# Predict model
xgpred <- predict(xgmodel, testtask)
performance(xgpred, measures = list(rmse))


```



```{r}
# Load required libraries
library(xgboost)
library(Matrix)


# Convert data to matrix format
train_matrix <- as.matrix(train_data %>% select(-pm2.5_atm))
train_label <- train_data$pm2.5_atm

test_matrix <- as.matrix(test_data %>% select(-pm2.5_atm))
test_label <- test_data$pm2.5_atm

# Create DMatrix objects
dtrain <- xgb.DMatrix(data = train_matrix, label = train_label)
dtest <- xgb.DMatrix(data = test_matrix, label = test_label)

# # Set parameters for xgboost
# params <- list(
#   objective = "reg:squarederror",
#   eta = 0.3,
#   max_depth = 6
# )
# # Train the model
# xgb_model <- xgb.train(
#   params = params,
#   data = dtrain,
#   nrounds = 100,
#   watchlist = list(train = dtrain, test = dtest),
#   early_stopping_rounds = 10,
#   verbose = 1
# )

# testing dif parameters
params <- list(
  objective = "reg:squarederror",
  eta = 0.1,  # Decreased learning rate
  max_depth = 4,  # Reduced tree depth
  alpha = 0.1,  # L1 regularization
  lambda = 1,  # L2 regularization
  min_child_weight = 5  # Increased minimum child weight
)

# Train the model with adjusted parameters
xgb_model <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = 200,  # Increased number of rounds
  watchlist = list(train = dtrain, test = dtest),
  early_stopping_rounds = 10,
  verbose = 1
)


# Make predictions
predictions <- predict(xgb_model, dtest)

# Calculate RMSE
rmse <- sqrt(mean((predictions - test_label)^2))
print(paste("RMSE:", rmse))

# FEATURE IMPORTANCE 
# Extract feature importance
importance_matrix <- xgb.importance(model = xgb_model)

# Print feature importance
print(importance_matrix)

# Plot feature importance
xgb.plot.importance(importance_matrix)
```

```{r}
# Assuming predictions and test_label are already defined

# Mean Absolute Error (MAE)
mae <- mean(abs(predictions - test_label))
print(paste("MAE:", mae))

# Mean Absolute Percentage Error (MAPE)
mape <- mean(abs((predictions - test_label) / test_label)) * 100
print(paste("MAPE:", mape))

# R-squared (R²)
ss_res <- sum((predictions - test_label)^2)
ss_tot <- sum((test_label - mean(test_label))^2)
r2 <- 1 - (ss_res / ss_tot)
print(paste("R²:", r2))

# Adjusted R-squared
n <- length(test_label)
p <- ncol(test_data) - 1  # assuming test_data doesn't include the target variable
adj_r2 <- 1 - ((1 - r2) * (n - 1) / (n - p - 1))
print(paste("Adjusted R²:", adj_r2))

# Root Mean Squared Error (RMSE)
rmse <- sqrt(mean((predictions - test_label)^2))
print(paste("RMSE:", rmse))

[1] "MAE: 5.84820260483082"
[1] "MAPE: Inf"
[1] "R²: -0.19407016056668"
[1] "Adjusted R²: -0.194096812105448"
[1] "RMSE: 10.4731686645913"
```


# LINEAR REGRESSION
# LINEAR REGRESSION
# LINEAR REGRESSION
# LINEAR REGRESSION
# LINEAR REGRESSION
# LINEAR REGRESSION


```{r}
# Linear Regression

# Load required libraries
library(caret)

# Split Train and Test data
set.seed(42)

# Define the time point at which to split the data (e.g., 70% for training)
split_time <- quantile(unique(dataset$time_stamp), 0.7)

# Split the data into training and testing sets based on the split_time
train_data <- subset(dataset, time_stamp <= split_time)
test_data <- subset(dataset, time_stamp > split_time)

train_data <- train_data %>% select(-time_stamp, -sensor_index)
test_data <- test_data %>% select(-time_stamp, -sensor_index)

print(colSums(is.na(train_data)))
train_data <- na.omit(train_data)

# Linear Regression Model
linear_model <- lm(pm2.5_atm ~ ., data = train_data)

# Summarize the model
summary(linear_model)

# Make predictions
linear_predictions <- predict(linear_model, newdata = test_data)

# Calculate performance metrics
# Mean Absolute Error (MAE)
mae_linear <- mean(abs(linear_predictions - test_label))
print(paste("Linear Regression MAE:", mae_linear))

# Mean Absolute Percentage Error (MAPE)
mape_linear <- mean(abs((linear_predictions - test_label) / test_label)) * 100
print(paste("Linear Regression MAPE:", mape_linear))

# R-squared (R²)
ss_res_linear <- sum((linear_predictions - test_label)^2)
ss_tot_linear <- sum((test_label - mean(test_label))^2)
r2_linear <- 1 - (ss_res_linear / ss_tot_linear)
print(paste("Linear Regression R²:", r2_linear))

# Adjusted R-squared
n_linear <- length(test_label)
p_linear <- ncol(test_data) - 1  # assuming test_data doesn't include the target variable
adj_r2_linear <- 1 - ((1 - r2_linear) * (n_linear - 1) / (n_linear - p_linear - 1))
print(paste("Linear Regression Adjusted R²:", adj_r2_linear))

# Root Mean Squared Error (RMSE)
rmse_linear <- sqrt(mean((linear_predictions - test_label)^2))
print(paste("Linear Regression RMSE:", rmse_linear))

# Compare with XGBoost performance
print(paste("XGBoost RMSE:", rmse))
print(paste("XGBoost MAE:", mae))
print(paste("XGBoost MAPE:", mape))
print(paste("XGBoost R²:", r2))
print(paste("XGBoost Adjusted R²:", adj_r2))


```




















# RANDOM FOREST
# RANDOM FOREST
# RANDOM FOREST
# RANDOM FOREST
# RANDOM FOREST
# RANDOM FOREST
# RANDOM FOREST
# RANDOM FOREST

# Random Forest Model (cant handle NAs)

```{r, eval=FALSE}
# Train random forest model
set.seed(42)
rf_model <- randomForest(pm2.5_atm ~ ., data = train_data, ntree = 500)

# Make random forest predictions
predictions_rf <- predict(rf_model, test_data)

# Mean Absolute Error

MAE <- mean(abs(predictions_rf - test_data$pm2.5_atm))

# Compute R squared

R2 <- 1 - sum((test_data$pm2.5_atm - predictions_rf)^2) / sum((test_data$pm2.5_atm - mean(test_data$pm2.5_atm))^2)

# Print R squared

cat("R squared:", R2)

# Visualize predictions

suppressPackageStartupMessages({
  library(ggplot2)
})

# plot(predictions_rf,test_data$pm2.5_atm)

ggplot(data = test_data, aes(x = pm2.5_atm, y = predictions_rf)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red") +  # Add a diagonal line for reference
  labs(x = "Actual PM2.5", y = "Predicted PM2.5") +
  ggtitle("Scatter Plot of Predicted vs. Actual PM2.5") +
  theme_minimal()
```

# Train XGBoost model
```{r, eval=FALSE}
suppressPackageStartupMessages({
  library(xgboost)
})
set.seed(42)
target_variable <- "pm2.5_atm"
predictor_variables <- setdiff(names(train_data), target_variable)

train_matrix <- xgb.DMatrix(data = as.matrix(train_data[, predictor_variables]), label = train_data[, target_variable])
test_matrix <- xgb.DMatrix(data = as.matrix(test_data[, predictor_variables]))

# Define XGBoost parameters
xgb_params <- list(
  objective = "reg:squarederror",  # For regression tasks
  eval_metric = "rmse",            # Root Mean Squared Error as the evaluation metric
  eta = 0.1,                       # Learning rate (adjust as needed)
  max_depth = 6,                   # Maximum depth of trees (adjust as needed)
  nrounds = 500,                   # Number of boosting rounds (adjust as needed)
  verbosity = 0                    # Set to 0 to suppress output
)

# Train the XGBoost model
xgb_model <- xgboost(data = train_matrix, params = xgb_params, nrounds = xgb_params$nrounds)

predictions_xgb <- predict(xgb_model, newdata = test_matrix)

# Calculate MAE
MAE <- mean(abs(predictions_xgb - test_data$pm2.5_atm))

# Calculate RMSE
RMSE <- sqrt(mean((predictions_xgb - test_data$pm2.5_atm)^2))

# Calculate R-squared (R²)
SSE <- sum((predictions_xgb - test_data$pm2.5_atm)^2)
SST <- sum((test_data$pm2.5_atm - mean(test_data$pm2.5_atm))^2)
R2 <- 1 - SSE / SST

cat("Mean Absolute Error (MAE):", MAE, "\n")
cat("Root Mean Squared Error (RMSE):", RMSE, "\n")
cat("R-squared (R²):", R2, "\n")

ggplot(data = test_data, aes(x = pm2.5_atm, y = predictions_xgb)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red") +  # Add a diagonal line for reference
  labs(x = "Actual PM2.5", y = "Predicted PM2.5") +
  ggtitle("Scatter Plot of Predicted vs. Actual PM2.5") +
  theme_minimal()
```

# XGBoost Feature importance
``` {r, eval=FALSE}
importance_scores <- xgb.importance(model = xgb_model)
xgb.plot.importance(importance_matrix = importance_scores)
```


# Investigate PM2.5 readings
``` {r, eval=FALSE}

hist_data <- hist(dataset$pm2.5_atm, breaks = 50, xlab = "PM2.5 Concentration", xaxt = 'n')
axis(side = 1, at = hist_data$mids, labels = hist_data$mids)

hist_table <- data.frame(
  Bin_Start = hist_data$breaks[-length(hist_data$breaks)],
  Bin_End = hist_data$breaks[-1],
  Frequency = hist_data$counts
)

# Print the histogram data as a table
print(hist_table)
```
